services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    environment:
      OLLAMA_BASE_URL: "http://host.docker.internal:11434"  # Communique avec le service Ollama
      OPENAI_API_URL: "http://pipelines:9099"  # Communique avec le service Pipelines
    volumes:
      - open-webui:/app/backend/data
      - ./open-webui:/app/backend/data
    networks:
      - webui-net

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    ports:
      - "9099:9099"
    volumes:
      - ./pipelines:/app/pipelines
      - ./data:/app/data
      - ./db:/app/db
      - ./src:/app/src
      - shared_data:/srv
      - ./data:/srv/data
      - ./.env:/app/.env
      - ./Logs:/app/Logs
      - open-webui:/app/backend/data
      - ./open-webui:/app/backend/data
    environment:
      - PIPELINES_DIR=/app/pipelines
      - PIPELINES_REQUIREMENTS_PATH=/app/pipelines/requirements.txt
      - PYTHONPATH=/app/src
    networks:
      - webui-net
    depends_on:
      - openwebui

networks:
  webui-net:

volumes:
  shared_data:
    driver: local
  open-webui:
    driver: local

